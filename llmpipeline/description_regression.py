dictionary_regression = {"Moneyball": "**Author**: MITx  \n\n**Source**: [Kaggle](https://www.kaggle.com/wduckett/moneyball-mlb-stats-19622012/data), originally from [The Analytics Edge course on EdX](https://www.edx.org/course/analytics-edge-mitx-15-071x-3). Data collected from [baseball-reference.com](baseball-reference.com)  \n\n**Please cite**:   \n\n\n\n**Moneyball**  \n\nIn the early 2000s, Billy Beane and Paul DePodesta worked for the Oakland Athletics. While there, they literally changed the game of baseball. They didn't do it using a bat or glove, and they certainly didn't do it by throwing money at the issue; in fact, money was the issue. They didn't have enough of it, but they were still expected to keep up with teams that had much deeper pockets. This is where Statistics came riding down the hillside on a white horse to save the day. This data set contains some of the information that was available to Beane and DePodesta in the early 2000s, and it can be used to better understand their methods.\n\n\n\n### Attributes  \n\nThis data set contains a set of variables that Beane and DePodesta focused heavily on. They determined that stats like on-base percentage (OBP) and slugging percentage (SLG) were very important when it came to scoring runs, however they were largely undervalued by most scouts at the time. This translated to a gold mine for Beane and DePodesta. Since these players weren't being looked at by other teams, they could recruit these players on a small budget. The variables are as follows:\n\n\n\nTeam  \n\nLeague  \n\nYear  \n\nRuns Scored (RS)  \n\nRuns Allowed (RA)  \n\nWins (W)  \n\nOn-Base Percentage (OBP)  \n\nSlugging Percentage (SLG)  \n\nBatting Average (BA)  \n\nPlayoffs (binary)  \n\nRankSeason  \n\nRankPlayoffs  \n\nGames Played (G)  \n\nOpponent On-Base Percentage (OOBP)  \n\nOpponent Slugging Percentage (OSLG)  \n\n\n\n### Acknowledgements  \n\nThis data set is referenced in The Analytics Edge course on EdX during the lecture regarding the story of Moneyball. The data itself is gathered from baseball-reference.com. Sports-reference.com is one of the most comprehensive sports statistics resource available, and I highly recommend checking it out.\n\n\n\nInspiration\n\nIt is such an important skill in today's world to be able to see the \"truth\" in a data set. That is what DePodesta was able to do with this data, and it unsettled the entire system of baseball recruitment. Beane and DePodesta defined their season goal as making it to playoffs. With that in mind, consider these questions:\n\n\n\nHow does a team make the playoffs?\n\nHow does a team win more games?\n\nHow does a team score more runs?\n\nThey are all simple questions with simple answers, but now it is time to use the data to find the \"truth\" hidden in the numbers.", "diamonds": "This classic dataset contains the prices and other attributes of almost 54,000 diamonds. It's a great dataset for beginners learning to work with data analysis and visualization.\n\nContent\nprice price in US dollars (\\$326--\\$18,823)\n\ncarat weight of the diamond (0.2--5.01)\n\ncut quality of the cut (Fair, Good, Very Good, Premium, Ideal)\n\ncolor diamond colour, from J (worst) to D (best)\n\nclarity a measurement of how clear the diamond is (I1 (worst), SI2, SI1, VS2, VS1, VVS2, VVS1, IF (best))\n\nx length in mm (0--10.74)\n\ny width in mm (0--58.9)\n\nz depth in mm (0--31.8)\n\ndepth total depth percentage = z / mean(x, y) = 2 * z / (x + y) (43--79)\n\ntable width of top of diamond relative to widest point (43--95)", "Allstate_Claims_Severity": "When you've been devastated by a serious car accident, your focus is on the things that matter the most: family, friends, and other loved ones. Pushing paper with your insurance agent is the last place you want your time or mental energy spent. This is why Allstate, a personal insurer in the United States, is continually seeking fresh ideas to improve their claims service for the over 16 million households they protect.\n\nAllstate is currently developing automated methods of predicting the cost, and hence severity, of claims. In this recruitment challenge, Kagglers are invited to show off their creativity and flex their technical chops by creating an algorithm which accurately predicts claims severity. Aspiring competitors will demonstrate insight into better ways to predict claims severity for the chance to be part of Allstate's efforts to ensure a worry-free customer experience.\n\nEach row in this dataset represents an insurance claim. You must predict the value for the 'loss' column. Variables prefaced with 'cat' are categorical, while those prefaced with 'cont' are continuous.", "Buzzinsocialmedia_Twitter": "**Author**: Creators :  Fran\u00e7ois Kawala (1\",\"2) Ahlame Douzal (1) Eric Gaussier (1) Eustache Diemert (2) Institutions :  (1) Universit\u00e9 Joseph Fourier (Grenoble I) Laboratoire d'informatique de Grenoble (LIG) (2) BestofMedia Group Donor:  BestofMedia (ediemert '@' bestofmedia.com)  \n**Source**: UCI \n**Please cite**: Pr&eacute;dictions d&rsquo;activit&eacute; dans les r&eacute;seaux sociaux en ligne (F. Kawala, A. Douzal-Chouakria, E. Gaussier, E. Dimert), In Actes de la Conf&eacute;rence sur les Mod&egrave;les et l&prime;Analyse des R&eacute;seaux : Approches Math&eacute;matiques et Informatique (MARAMI), pp. 16, 2013.  \n\nAbstract: This data-set contains examples of buzz events from two different social networks: Twitter, and Tom's Hardware, a forum network focusing on new technology with more conservative dynamics.\nSource:\n\nCreators : \nFran&ccedil;ois Kawala (1,2) Ahlame Douzal (1) Eric Gaussier (1) Eustache Diemert (2)\nInstitutions : \n(1) Universit&eacute; Joseph Fourier (Grenoble I)\nLaboratoire d'informatique de Grenoble (LIG)\n(2) BestofMedia Group\nDonor: \nBestofMedia (ediemert '@' bestofmedia.com)\n\n\nData Set Information:\n\nPlease see [Web Link]\n\n\nAttribute Information:\n\nPlease see [Web Link]\n\n\nRelevant Papers:\n\nPr&eacute;dictions d&rsquo;activit&eacute; dans les r&eacute;seaux sociaux en ligne (F. Kawala, A. Douzal-Chouakria, E. Gaussier, E. Dimert), In Actes de la Conf&eacute;rence sur les Mod&egrave;les et l&prime;Analyse des R&eacute;seaux : Approches Math&eacute;matiques et Informatique (MARAMI), pp. 16, 2013.\n\n\n\nCitation Request:\n\nPr&eacute;dictions d&rsquo;activit&eacute; dans les r&eacute;seaux sociaux en ligne (F. Kawala, A. Douzal-Chouakria, E. Gaussier, E. Dimert), In Actes de la Conf&eacute;rence sur les Mod&egrave;les et l&prime;Analyse des R&eacute;seaux : Approches Math&eacute;matiques et Informatique (MARAMI), pp. 16, 2013.", "Santander_transaction_value": "According to Epsilon research, 80% of customers are more likely to do business with you if you provide personalized service. Banking is no exception.\n\nThe digitalization of everyday lives means that customers expect services to be delivered in a personalized and timely manner... and often before they've even realized they need the service. In their 3rd Kaggle competition, Santander Group aims to go a step beyond recognizing that there is a need to provide a customer a financial service and intends to determine the amount or value of the customer's transaction. This means anticipating customer needs in a more concrete, but also simple and personal way. With so many choices for financial services, this need is greater now than ever before.\n\nIn this competition, Santander Group is asking Kagglers to help them identify the value of transactions for each potential customer. This is a first step that Santander needs to nail in order to personalize their services at scale.\n\nYou are provided with an anonymized dataset containing numeric feature variables, the numeric target column, and a string ID column.\n\nThe task is to predict the value of target column.", "Mercedes_Benz_Greener_Manufacturing": "Since the first automobile, the Benz Patent Motor Car in 1886, Mercedes-Benz has stood for important automotive innovations. These include, for example, the passenger safety cell with crumple zone, the airbag and intelligent assistance systems. Mercedes-Benz applies for nearly 2000 patents per year, making the brand the European leader among premium car makers. Daimler's Mercedes-Benz cars are leaders in the premium car industry. With a huge selection of features and options, customers can choose the customized Mercedes-Benz of their dreams.\n\nTo ensure the safety and reliability of each and every unique car configuration before they hit the road, Daimler's engineers have developed a robust testing system. But, optimizing the speed of their testing system for so many possible feature combinations is complex and time-consuming without a powerful algorithmic approach. As one of the world's biggest manufacturers of premium cars, safety and efficiency are paramount on Daimler's production lines.\n\nIn this competition, Daimler is challenging Kagglers to tackle the curse of dimensionality and reduce the time that cars spend on the test bench. Competitors will work with a dataset representing different permutations of Mercedes-Benz car features to predict the time it takes to pass testing. Winning algorithms will contribute to speedier testing, resulting in lower carbon dioxide emissions without reducing Daimler's standards.\n\nThis dataset contains an anonymized set of variables, each representing a custom feature in a Mercedes car. For example, a variable could be 4WD, added air suspension, or a head-up display.\n\nThe ground truth is labeled 'y' and represents the time (in seconds) that the car took to pass testing for each variable.", "Yolanda": "**Author**: Universite Paris-Saclay  \n\n**Source**: [original](https://automl.chalearn.org/data) - 20-02-2016  \n\n**Please cite**: Guyon I. et al. (2019) Analysis of the AutoML Challenge Series 2015\u20132018. In: Hutter F., Kotthoff L., Vanschoren J. (eds) Automated Machine Learning. The Springer Series on Challenges in Machine Learning. Springer, Cham. https://doi.org/10.1007/978-3-030-05318-5_10\n\n\n\nAutoML challenge 2014. \n\n\n\nOriginal task: regression.\n\n\n\nTest and validation sets can be obtained on the Cha Learn website: https://automl.chalearn.org/data", "Airlines_DepDelay_10M": "Airlines Departure Delay Prediction (Regression). Original data can be found at: http://www.transtats.bts.gov\n\n\n\nThis is a processed version of the original data, designed to predict departure delay (in seconds).\n\n\n\nA CSV of the raw data (years 1987-2013) can be be found here. This is the first 10 million rows (and a subset of the columns) of this CSV file, in ARFF format.", "quake": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nFile README\n-----------\n\nsmoothmeth  A collection of the data sets used in the book \"Smoothing\nMethods in Statistics,\" by Jeffrey S. Simonoff,\nSpringer-Verlag, New York, 1996. Submitted by Jeff\nSimonoff (jsimonoff@stern.nyu.edu).\n\n\nThis submission consists of 37 files, plus this README file.\nEach file represents a data set analyzed in the book.\nThe names of the files correspond to the names given in\nthe book. The data files are written in plain ASCII (character)\ntext. Missing values are represented by \"M\" in all data files.\n\nSeveral of the files include an alphabetic (labeling) variable. It is\nlikely that these files would have to be input into a package using fixed,\nrather than free, format. The relevant files, along with appropriate\nFortran format statements, are as follows:\n\nadptvisa.dat: (f10.4,4x,f7.4,3x,a20)\n\nairaccid.dat: (i3,3x,a34)\n\nbasesal.dat : (f8.1,4x,a17)\n\nbaskball.dat: (f7.4,4x,f6.4,3x,i3,4x,f5.2,3x,i2,3x,a17)\n\ncars93.dat  : (f5.1,2x,i2,2x,i2,3x,f3.1,2x,i3,3x,f4.1,2x,i4,2x,a21)\n\nelusage.dat : (i4,3x,f7.3,2x,a7)\n\nhckshoot.dat: (f7.3,4x,i1,4x,a20)\n\njantemp.dat : (i6,3x,a30)\n\nmarathon.dat: (f10.2,4x,a27)\n\nnewscirc.dat: (f8.2,3x,f7.2,2x,a25)\n\nracial.dat  : (f7.4,4x,a32)\n\nsafewatr.dat: (i5,3x,i3,3x,a26)\n\nschlvote.dat: (i3,4x,f5.2,2x,i8,4x,f4.1,5x,f5.2,2x,i7,2x,a25)\n\nDescription of data sources, and further information about the data sets,\ncan be found in the \"Descriptions of the data sets\" section of the book.\nPointing a World Wide Web browser to the URL\n\nhttp://www.stern.nyu.edu/SOR/SmoothMeth\n\nwill provide access to a site devoted to the book.\n\nNOTICE: These datasets may be used freely for scientific,\neducational and/or non-commercial purposes, provided suitable\nacknowledgment is given (by citing the reference above).\n\n\nFile: ../data/smoothmeth/quake.dat\n\n\nInformation about the dataset\nCLASSTYPE: numeric\nCLASSINDEX: none specific", "sensory": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nData for the sensory evaluation experiment in Brien, C.J. and Payne,\nR.W. (1996) Tiers, structure formulae and the analysis of complicated\nexperiments.  submitted for publication.\nThe experiment involved two phases.  In the field phase a viticultural\nexperiment was conducted to investigate the differences between 4\ntypes of trellising and 2 methods of pruning.  The design was a\nsplit-plot design in which the trellis types were assigned to the main\nplots using two adjacent Youden squares of 3 rows and 4 columns.  Each\nmain plot was split into two subplots (or halfplots) and the methods\nof pruning assigned at random independently to the two halfplots in\neach main plot.  The produce of each halfplot was made into a wine so\nthat there were 24 wines altogether.\nThe second phase was an evaluation phase in which the produce from the\nhalplots was evaluated by 6 judges all of whom took part in 24\nsittings.  In the first 12 sittings the judges evaluated the wines\nmade from the halfplots of one square; the final 12 sittings were to\nevaluate the wines from the other square.  At each sitting, each judge\nassessed two glasses of wine from each of the halplots of one of the\nmain plots.  The main plots allocated to the judges at each sitting\nwere determined as follows.  For the allocation of rows, each occasion\nwas subdivided into 3 intervals of 4 consecutive sittings.  During\neach interval, each judge examined plots from one particular row,\nthese being determined using two 3x3 Latin squares for each occasion,\none for judges 1-3 and the other for judges 4-6.  At each sitting\njudges 1-3 examined wines from one particular column and judges 4-6\nexamined wines from another column.  The columns were randomized to\nthe 2 sets of judges x 3 intervals x 4 sittings using duplicates of a\nbalanced incomplete block design for v=4 and k=2 that were latinized.\nThis balanced incomplete block design consists of three sets of 2\nblocks, each set containing the 4 \"treatments\".  For each interval, a\ndifferent set of 2 blocks was taken and each block assigned to two\nsittings, but with the columns within the block placed in reverse\norder in one sitting compared to the other sitting.  Thus, in each\ninterval, a judge would evaluate a wine from each of the 4 columns.\nThe scores assigned in evaluating the wines, and the factors indexing\nthem, are given below.  The factors are as follows:\nOccasion\nJudges\nInterval\nSittings\nPosition\nSquares\nRows\nColumns\nHalfplot\nTrellis\nMethod\nfollowed by the response variable\nScore\nThe scores are ordered so that the factors Occasion, Judges, Interval,\nSittings and Position are in standard order; the remaining factors are\nin randomized order.\n\n\nInformation about the dataset\nCLASSTYPE: numeric\nCLASSINDEX: last", "socmob": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\n17x17x2x2 tables of counts in GLIM-ready format used for the analyses\nin Biblarz, Timothy J., and Adrian E. Raftery. 1993. \"The Effects of\nFamily Disruption on Social Mobility.\" American Sociological Review\n(In press). For further details of the data, see this reference.\nColumn 1 is father's occupation, coded as follows:\n17. Professional, Self-Employed\n16. Professional-Salaried\n15. Manager\n14. Salesman-Nonretail\n13. Proprietor\n12. Clerk\n11. Salesman-Retail\n10. Craftsman-Manufacturing\n9. Craftsmen-Other\n8. Craftsman-Construction\n7. Service Worker\n6. Operative-Nonmanufacturing\n5. Operative-Manufacturing\n4. Laborer-Manufacturing\n3. Laborer-Nonmanufacturing\n2. Farmer/Farm Manager\n1. Farm Laborer\nColumn 2 is son's occupation, coded in the same way as father's.\nColumn 3 is family structure, coded 1=intact family background and\n2=nonintact family background.\nColumn 4 is race, coded 1=white and 2=black.\nColumn 5 is counts for son's first occupation.\nColumn 6 is counts for son's current occupation.\nThe counts have been weighted to take account of the survey\ndesign, which is why they are not integers.\n************************************************************\n***********************************************************\nThis file was constructed from publicly available data collected\nby David Featherman and Robert Hauser in 1973: the \"Occupational\nChange in a Generation II\" (OCG II) Survey. Permission is hereby given to\nuse the above data for non-commercial scholarly and teaching purposes.\nIf these data are used in a published article or book,\nthe authors, the original data (in the form given in\nBiblarz and Raftery (1993), cited above), and StatLib should\nall be acknowledged.\n\n\nInformation about the dataset\nCLASSTYPE: numeric\nCLASSINDEX: none specific", "space_ga": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nGeographical Analysis Spatial Data\n\nThis georeferenced data set was used in:\n\nPace, R. Kelley, and Ronald Barry, Quick Computation of Regressions with a Spatially\nAutoregressive Dependent Variable, Geographical Analysis, Volume 29, Number 3, July\n1997, p. 232-247.\n\nIt contains 3,107 observations on U.S. county votes cast in the 1980 presidential election.\nSpecifically, it contains the total number of votes cast in the 1980 presidential election per\ncounty (VOTES), the population in each county of 18 years of age or older (POP), the\npopulation in each county with a 12th grade or higher education (EDUCATION), the\nnumber of owner-occupied housing units (HOUSES), the aggregate income (INCOME), the X\nspatial coordinate of the county (XCOORD), and the Y spatial coordinate of the county\n(YCOORD).\n\nThe dependent variable is the log of the proportion of votes cast for both candidates in the\n1980 presidential election. Hence, we can express our dependent variable as ln(VOTES/\nPOP) = ln(VOTES)-ln(POP).\n\nThe overall data set has the following structure\n\n[ln(VOTES/POP) POP EDUCATION HOUSES INCOME XCOORD YCOORD]\n\nAdditional details can be found, along with other data, manuscripts, free spatial software, and\nso forth, at www.spatial-statistics.com or www.finance.lsu.edu/re (follow the spatial statistics\nlink). In particular, the above mentioned manuscript which used the data is available for\ndownload. If you have any questions, send an email to kelley@spatial-statistics.com.\n\n\n\n\n\n\nInformation about the dataset\nCLASSTYPE: numeric\nCLASSINDEX: 1", "tecator": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nThis is the Tecator data set: The task is to predict the fat content of a\nmeat sample on the basis of its near infrared absorbance spectrum.\n1. Statement of permission from Tecator (the original data source)\n\nThese data are recorded on a Tecator Infratec Food and Feed Analyzer\nworking in the wavelength range 850 - 1050 nm by the Near Infrared\nTransmission (NIT) principle. Each sample contains finely chopped pure\nmeat with different moisture, fat and protein contents.\n\nIf results from these data are used in a publication we want you to\nmention the instrument and company name (Tecator) in the publication.\nIn addition, please send a preprint of your article to\n\nKarin Thente, Tecator AB,\nBox 70, S-263 21 Hoganas, Sweden\n\nThe data are available in the public domain with no responsability from\nthe original data source. The data can be redistributed as long as this\npermission note is attached.\nFor more information about the instrument - call Perstorp Analytical's\nrepresentative in your area.\n\n\n2. Description of the data file\n\nFor each meat sample the data consists of a 100 channel spectrum of\nabsorbances and the contents of moisture (water), fat and protein.\nThe absorbance is -log10 of the transmittance\nmeasured by the spectrometer. The three contents, measured in percent,\nare determined by analytic chemistry.\n\nThere are 240 samples which are divided into 5 data sets for the purpose\nof model validation and extrapolation studies. The data sets, further\ndescribed in reference 1, are:\n\nData set  Use               Samples\nC         Traning               129\nM         Monitoring             43\nT         Testing                43\nE1        Extrapolation, Fat      8\nE2        Extrapolation, Protein 17\n\nThe data for all 240 samples appear at the end of this file - 25 lines\nper sample. The data sets appear in the order of the table above.\nThe spectra are preprocessed using a principal component analysis on the\ndata set C, and the first 22 principal components (scaled to unit\nvariance) are included for each sample.\nThus if you want to use the data for a standard (interpolation) test\nof your algorithm, use sample 1-172 for training and sample 173-215\nfor testing (and ignore the last 25 samples), and use the first 13 or so\nprincipal components to predict the fat content.\n\nEach line contains the 100 absorbances followed by the 22 principal\ncomponents and finally the contents of moisture, fat and protein.\n\nPreceeding the data lines, the following lines appear:\n\nreal_in=122\nreal_out=3\ntraining_examples=172\ntest_examples=43\nextrapolation_examples=25\n\n\n3. More details on how to use the data\n\nThe data are made available as a benchmark for regression models. In order\nto compare models, it is practical to use the data set as follows:\n\nC and M combined are used to tune (estimate, train) the model. (Some\napproaches set aside some training data to control overfitting. These data\nshould be a subset of C+M. In (1) the subset M was used for this purpose.)\n\nT is used to test the model once it has been tuned.\nIf each model has an element of randomness (as is the case\nfor neural networks) the most reliable measure of performance of a single\nmodel is obtained by selecting a handful of models on the basis of C+M and\nquoting the average of the performances on T.\nIn the presence of randomness it is bad practice to train a lot of models\non C+M and then select the best of these on the basis of T.\n\nC, M and T are drawn from the same pool of data, so T is used to test the\nability of the models to interpolate. The data sets E1 and E2 contain\nmore fat and protein respectively and are intended to be used to test the\nability of the models to extrapolate.\n\n\n4. Performance of neural network models\n\nThe performance is measured as Standard Error of Prediction (SEP) which\nis the root mean square of the difference between the true and the predicted\ncontent.\n\nFor the prediction of fat on the data set T the following results were obtained\n\nReference SEP   method (see the papers for details)\n(1)       0.65  10-6-1 network, early stopping\n(2)       0.52  10-3-1 network, Bayesian\n(3)       0.36  13-X-1 network, Bayesian, Automatic Relevance Determination\n\nA linear model with 10 inputs yields SEP=2.78.\n\n5. References\n\n(1) C.Borggaard and H.H.Thodberg,\n\"Optimal Minimal Neural Interpretation of Spectra\",\nAnalytical Chemistry 64 (1992), p 545-551.\n(2) H.H.Thodberg, \"Ace of Bayes: Application of Neural Networks with Pruning\"\nManuscript 1132, Danish Meat Research Institute (1993),\navailable by anonymous ftp in the file:\npub/neuroprose/thodberg.ace-of-bayes.ps.Z on the Internet node\narchive.cis.ohio-state.edu (128.146.8.52).\n\n(3) Revised and extended version of (2), in preparation, to be\nsubmitted to IEEE Trans. Neural Networks (1995)\navailable by anonymous ftp in the file:\npub/neuroprose/thodberg.bayesARD.ps.Z on the Internet node\narchive.cis.ohio-state.edu (128.146.8.52).\n\nHans Henrik Thodberg                Email: thodberg@nn.dmri.dk\nDanish Meat Research Institute      Phone: (+45) 42 36 12 00\nMaglegaardsvej 2, Postboks 57       Fax:   (+45) 42 36 48 36\nDK-4000 Roskilde, Denmark\n\nreal_in=122\nreal_out=3\ntraining_examples=172\ntest_examples=43\nextrapolation_examples=25\n\n\nNote: all 240 samples are included in the same order as mentioned above\n\n\nInformation about the dataset\nCLASSTYPE: numeric\nCLASSINDEX: none specific", "wine_quality": "**Author**: Tobias Kuehn  \n**Source**: Unknown - 2009  \n**Please cite**:   \n\n1. Title: Wine Quality \n\n2. Sources\nCreated by: Paulo Cortez (Univ. Minho), Antonio Cerdeira, Fernando Almeida, Telmo Matos and Jose Reis (CVRVV) @ 2009\n    \n3. Past Usage:\nP. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis. \nModeling wine preferences by data mining from physicochemical properties.\nIn Decision Support Systems, Elsevier, 47(4):547-553. ISSN: 0167-9236.\n\nIn the above reference, two datasets were created, using red and white wine samples.\nThe inputs include objective tests (e.g. PH values) and the output is based on sensory data (median of at least 3 evaluations made by wine experts). Each expert graded the wine quality between 0 (very bad) and 10 (very excellent). Several data mining methods were applied to model these datasets under a regression approach. The support vector machine model achieved the best results. Several metrics were computed: MAD, confusion matrix for a fixed error tolerance (T), etc. Also, we plot the relative importances of the input variables (as measured by a sensitivity analysis procedure).\n \n4. Relevant Information:\nThe two datasets are related to red and white variants of the Portuguese \"Vinho Verde\" wine. For more details, consult: http://www.vinhoverde.pt/en/ or the reference [Cortez et al., 2009]. Due to privacy and logistic issues, only physicochemical (inputs) and sensory (the output) variables  are available (e.g. there is no data about grape types, wine brand, wine selling price, etc.).\nThese datasets can be viewed as classification or regression tasks.\nThe classes are ordered and not balanced (e.g. there are munch more normal wines than excellent or poor ones). Outlier detection algorithms could be used to detect the few excellent or poor wines. Also, we are not sure if all input variables are relevant. So it could be interesting to test feature selection methods. \n\n5. Number of Instances: red wine - first 1599 instances; white wine - instances 1600 to 6497. \n \n6. Number of Attributes: 11 + output attribute\nNote: several of the attributes may be correlated, thus it makes sense to apply some sort of feature selection.\n\n7. Attribute information:\nFor more information, read [Cortez et al., 2009].\nInput variables (based on physicochemical tests):\n1 - fixed acidity\n2 - volatile acidity\n3 - citric acid\n4 - residual sugar\n5 - chlorides\n6 - free sulfur dioxide\n7 - total sulfur dioxide\n8 - density\n9 - pH\n10 - sulphates\n11 - alcohol\nOutput variable (based on sensory data): \n12 - quality (score between 0 and 10)\n\n8. Missing Attribute Values: None", "elevators": "This data set is also obtained from the task of controlling a F16\naircraft, although the target variable and attributes are different\nfrom the ailerons domain. In this case the goal variable is related to\nan action taken on the elevators of the aircraft.", "black_friday": "Customer purchases on Black Friday", "Brazilian_houses": "**Author**: Kaggle  \n\n**Source**: [original](https://www.kaggle.com/rubenssjr/brasilian-houses-to-rent) - 20-03-2020  \n\n**Please cite**:   \n\n\n\nThis dataset contains 10962 houses to rent with 13 diferent features.\n\n\n\n**Outliers **\n\nSome values in the dataset can be considered as outliers for further analyses. Bear in mind that the Web Crawler was used only to get the data, so it's possible that errors in the original data exist.\n\n\n\n**Changes in data between versions of dataset **\n\nSince the WebCrawler was ran in different days for each version of dataset, there may be differences like added or deleted houses (as well as added cities).\n\n\n\nNotes: \n\n\n\n1) This dataset corresponds to the 2nd version of the original dataset (\"houses_to_rent_v2.csv\").\n\n\n\n2) The value '-' in the attribute floor was replaced by '0' as the data contributor stated that this refers to houses with just one floor (see https://www.kaggle.com/rubenssjr/brasilian-houses-to-rent/discussion).", "topo_2_1": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nThis is one of 41 drug design datasets. The datasets with 1143 features are formed using Adriana.Code software  (www.molecular-networks.com/software/adrianacode).\nThe molecules and outputs are taken from the original studies (see below). The other datasets are taken exactly from the original studies. \n\nThe last attribute in each file is the target.\n\nOriginal studies:\n\ncarbolenes\n\"B. D. Silverman and Daniel. E. Platt, J. Med. Chem. 1996, 39, 2129-2140\"\n\nmtp2\n\"Bergstrom, C. A. S.; Norinder, U.; Luthman, K.; Artursson, P. Molecular Descriptors Influencing Melting Point and Their Role in Classification of Solid Drugs. J. Chem. Inf. Comput. Sci.; (Article); 2003; 43(4); 1177-1185\"\n\nchang, cristalli, depreux, doherty, garrat2, garrat, heyl, krystek, lewis, penning, rosowsky, siddiqi, stevenson, strupcz, svensson, thompson, tsutumi, uejling, yokoyama1, yokoyama2\t\n\"David E Patterson, Richard D Cramer, Allan M Ferguson, Robert D Clark, Laurence W Weinberger. Neighbourhood Behaviour: A Useful Concept for Validation of \"\"Molecular Diversity\"\" Descriptors. J. Med. Chem. 1996 (39) 3049 - 3059.\"\n\nmtp\n\"Karthikeyan, M.; Glen, R.C.; Bender, A. General melting point prediction based on a diverse compound dataset and artificial neural networks. J. Chem. Inf. Model.; 2005; 45(3); 581-590\"\n\nbenzo32\n\"Harrison,P.W. and Barlin,G.B. and Davies,L.P. and Ireland,S.J. and Matyus,P. and Wong,M.G., Syntheses, pharmacological evaluation and molecular modelling of substituted 6-alkoxyimidazo[1,2-b]pyridazines as new ligands for the benzodiazepine receptor, European Journal of Medicinal Chemistry, (31), 1996, 651-662\"\n\nPHENETYL1\t\n\"H. Kubinyi (Ed.): \"\"QSAR: Hansch Analysis and Related Approaches\"\", VCH, Weinhein (Ger), 1993, pp.57-68\"\n\npah\t\n\"Todeschini, R.; Gramatica, P.; Marengo, E.; Provenzani, R. Weighted Holistic  Invariant Molecular Descriptors. Part 2. Theory Development and Applications on Modeling Physico-Chemical Properties of PolyAromatic Hydrocarbons (PAH). Chemom. Intell. Lab. Syst. 1995, 27, 221-229.\"\n\npdgfr\t\n\"R. Guha and P. Jurs. The Development of Linear, Ensemble and Non-linear Models for the Prediction and Interpretation of the Biological Activity of a Set of PDGFR Inhibitors. J. Chem. Inf. Comput. Sci. 2004, 44 (6), 2179-2189\"\n\nPhen\t\n\"Cammarata, A. Interrelationship of the Regression Models Used for Structure-Activity Analyses. J. Med. Chem. 1972, 15, 573-577\"\n\ntopo_2_1, yprop_4_1\t\n\"Jun Feng et al, Predictive Toxicology: Benchmarking Molecular Descriptors and Statistical Methods, J. Chem. Inf Comput. Sci., 2003 (43) 1463-1470\"\n\nqsabr1, qsabr2\t\n\"Damborsky, J., Schultz, T.W., Comparison of the QSAR models for toxicity and biodegradability of anilines and phenols, Chemosphere 34: 429-446, 1997\"\n\nqsartox\t\n\"Blaha, L., Damborsky, J., Nemec, M., QSAR for acute toxicity of saturated and unsaturated halogenated aliphatic compounds, Chemosphere 36: 1345-1365, 1998\"\n\nqsbr_rw1\t\n\"Damborsky, J. et al., Structure-biodegradability relationships for chlorinated dibenzo-p-dioxins and dibenzofurans, In: Wittich, R.-M., Biodegradation of dioxins and furans, R.G. Landes Company, Austin, 1998\"\n\nqsbr_y2\t\n\"Damborsky, J. et al., A mechanistic approach to deriving QSBR- A case study: dehalogenation of haloaliphatic compounds, In: Peijnenburg, W.J.G.M., Damborsky, J., Biodegradability Prediction, Kluwer Academic Publishers\"\n\nqsbralks\t\n\"Damborsky, J. et al., Mechanism-based Quantitative Structure-Biodegradability Relationships for hydrolytic dehalogenation of chloro- and bromo-alkenes, Quantitative Structure-Activity Relationships 17: 450-458, 1998\"\n\nqsfrdhla\t\n\"Damborsky, J., Quantitative structure-function relationships of the single-point mutants of haloalkane dehalogenase: A multivariate approach, Qunatitative Structure-Activity Relationships 16: 126-135, 1997\"\n\nqsfsr1\t\n\"Damborsky, J., Quantitative structure-function and structure-stability relationships of purposely modified proteins, Protein Engineering 11: 21-30, 1998\"\n\nqsfsr2\t\n\"Damborsky, J., Quantitative structure-function and structure-stability relationships of purposely modified proteins, Protein Engineering 11: 21-30, 1998\"\n\nqsprcmpx\t\n\"Cajan, M. et al., Stability of Aromatic Amides with Bromide Anion: Quantitative Structure-Property Relationships, Journal of Chemical Information and Computer Sciences, in press, 2000\"\n\nselwood\t\n\"Selwood, D. L.; Livingstone, D. J.; Comley, J. C.; O'Dowd, A. B.; Hudson, A. T.; Jackson, P.; Jandu, K. S.; Rose, V. S.; Stables, J. N. Structure-Activity Relationships of Antifilarial Antimycin Analogues: A Multivariate Pattern Recognition Study J. Med. Chem., 1990, 33, 136-142\"", "yprop_4_1": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nThis is one of 41 drug design datasets. The datasets with 1143 features are formed using Adriana.Code software  (www.molecular-networks.com/software/adrianacode).\nThe molecules and outputs are taken from the original studies (see below). The other datasets are taken exactly from the original studies. \n\nThe last attribute in each file is the target.\n\nOriginal studies:\n\ncarbolenes\n\"B. D. Silverman and Daniel. E. Platt, J. Med. Chem. 1996, 39, 2129-2140\"\n\nmtp2\n\"Bergstrom, C. A. S.; Norinder, U.; Luthman, K.; Artursson, P. Molecular Descriptors Influencing Melting Point and Their Role in Classification of Solid Drugs. J. Chem. Inf. Comput. Sci.; (Article); 2003; 43(4); 1177-1185\"\n\nchang, cristalli, depreux, doherty, garrat2, garrat, heyl, krystek, lewis, penning, rosowsky, siddiqi, stevenson, strupcz, svensson, thompson, tsutumi, uejling, yokoyama1, yokoyama2\t\n\"David E Patterson, Richard D Cramer, Allan M Ferguson, Robert D Clark, Laurence W Weinberger. Neighbourhood Behaviour: A Useful Concept for Validation of \"\"Molecular Diversity\"\" Descriptors. J. Med. Chem. 1996 (39) 3049 - 3059.\"\n\nmtp\n\"Karthikeyan, M.; Glen, R.C.; Bender, A. General melting point prediction based on a diverse compound dataset and artificial neural networks. J. Chem. Inf. Model.; 2005; 45(3); 581-590\"\n\nbenzo32\n\"Harrison,P.W. and Barlin,G.B. and Davies,L.P. and Ireland,S.J. and Matyus,P. and Wong,M.G., Syntheses, pharmacological evaluation and molecular modelling of substituted 6-alkoxyimidazo[1,2-b]pyridazines as new ligands for the benzodiazepine receptor, European Journal of Medicinal Chemistry, (31), 1996, 651-662\"\n\nPHENETYL1\t\n\"H. Kubinyi (Ed.): \"\"QSAR: Hansch Analysis and Related Approaches\"\", VCH, Weinhein (Ger), 1993, pp.57-68\"\n\npah\t\n\"Todeschini, R.; Gramatica, P.; Marengo, E.; Provenzani, R. Weighted Holistic  Invariant Molecular Descriptors. Part 2. Theory Development and Applications on Modeling Physico-Chemical Properties of PolyAromatic Hydrocarbons (PAH). Chemom. Intell. Lab. Syst. 1995, 27, 221-229.\"\n\npdgfr\t\n\"R. Guha and P. Jurs. The Development of Linear, Ensemble and Non-linear Models for the Prediction and Interpretation of the Biological Activity of a Set of PDGFR Inhibitors. J. Chem. Inf. Comput. Sci. 2004, 44 (6), 2179-2189\"\n\nPhen\t\n\"Cammarata, A. Interrelationship of the Regression Models Used for Structure-Activity Analyses. J. Med. Chem. 1972, 15, 573-577\"\n\ntopo_2_1, yprop_4_1\t\n\"Jun Feng et al, Predictive Toxicology: Benchmarking Molecular Descriptors and Statistical Methods, J. Chem. Inf Comput. Sci., 2003 (43) 1463-1470\"\n\nqsabr1, qsabr2\t\n\"Damborsky, J., Schultz, T.W., Comparison of the QSAR models for toxicity and biodegradability of anilines and phenols, Chemosphere 34: 429-446, 1997\"\n\nqsartox\t\n\"Blaha, L., Damborsky, J., Nemec, M., QSAR for acute toxicity of saturated and unsaturated halogenated aliphatic compounds, Chemosphere 36: 1345-1365, 1998\"\n\nqsbr_rw1\t\n\"Damborsky, J. et al., Structure-biodegradability relationships for chlorinated dibenzo-p-dioxins and dibenzofurans, In: Wittich, R.-M., Biodegradation of dioxins and furans, R.G. Landes Company, Austin, 1998\"\n\nqsbr_y2\t\n\"Damborsky, J. et al., A mechanistic approach to deriving QSBR- A case study: dehalogenation of haloaliphatic compounds, In: Peijnenburg, W.J.G.M., Damborsky, J., Biodegradability Prediction, Kluwer Academic Publishers\"\n\nqsbralks\t\n\"Damborsky, J. et al., Mechanism-based Quantitative Structure-Biodegradability Relationships for hydrolytic dehalogenation of chloro- and bromo-alkenes, Quantitative Structure-Activity Relationships 17: 450-458, 1998\"\n\nqsfrdhla\t\n\"Damborsky, J., Quantitative structure-function relationships of the single-point mutants of haloalkane dehalogenase: A multivariate approach, Qunatitative Structure-Activity Relationships 16: 126-135, 1997\"\n\nqsfsr1\t\n\"Damborsky, J., Quantitative structure-function and structure-stability relationships of purposely modified proteins, Protein Engineering 11: 21-30, 1998\"\n\nqsfsr2\t\n\"Damborsky, J., Quantitative structure-function and structure-stability relationships of purposely modified proteins, Protein Engineering 11: 21-30, 1998\"\n\nqsprcmpx\t\n\"Cajan, M. et al., Stability of Aromatic Amides with Bromide Anion: Quantitative Structure-Property Relationships, Journal of Chemical Information and Computer Sciences, in press, 2000\"\n\nselwood\t\n\"Selwood, D. L.; Livingstone, D. J.; Comley, J. C.; O'Dowd, A. B.; Hudson, A. T.; Jackson, P.; Jandu, K. S.; Rose, V. S.; Stables, J. N. Structure-Activity Relationships of Antifilarial Antimycin Analogues: A Multivariate Pattern Recognition Study J. Med. Chem., 1990, 33, 136-142\"", "OnlineNewsPopularity": "Version with url set as row id, creator data missing due to bad formatting.**Author**: Kelwin Fernandes (INESC TEC, Universidade doPorto), Pedro Vinagre (ALGORITMI Research Centre, Universidade do Minho), Paulo Cortez - ALGORITMI Research Centre (Universidade do Minho), Pedro Sernadela (Universidade de Aveiro)   \n\n**Source**: UCI  \n\n**Please cite**: K. Fernandes, P. Vinagre and P. Cortez. A Proactive Intelligent Decision Support System for Predicting the Popularity of Online News. Proceedings of the 17th EPIA 2015 - Portuguese Conference on Artificial Intelligence, September, Coimbra, Portugal.  \n\n\n\nThis dataset summarizes a heterogeneous set of features about articles published by Mashable in a period of two years. The goal is to predict the number of shares in social networks (popularity).\n\n\n\n* The articles were published by Mashable (www.mashable.com) and their content as the rights to reproduce it belongs to them. Hence, this dataset does not share the original content but some statistics associated with it. The original content be publicly accessed and retrieved using the provided urls. \n\n* Acquisition date: January 8, 2015 \n\n* The estimated relative performance values were estimated by the authors using a Random Forest classifier and a rolling windows as assessment method. See their article for more details on how the relative performance values were set.\n\n\n\n\n\nAttribute Information:\n\n\n\nNumber of Attributes: 61 (58 predictive attributes, 2 non-predictive, 1 goal field) \n\n\n\nAttribute Information: \n\n0. url: URL of the article (non-predictive) \n\n1. timedelta: Days between the article publication and the dataset acquisition (non-predictive) \n\n2. n_tokens_title: Number of words in the title \n\n3. n_tokens_content: Number of words in the content \n\n4. n_unique_tokens: Rate of unique words in the content \n\n5. n_non_stop_words: Rate of non-stop words in the content \n\n6. n_non_stop_unique_tokens: Rate of unique non-stop words in the content \n\n7. num_hrefs: Number of links \n\n8. num_self_hrefs: Number of links to other articles published by Mashable \n\n9. num_imgs: Number of images \n\n10. num_videos: Number of videos \n\n11. average_token_length: Average length of the words in the content \n\n12. num_keywords: Number of keywords in the metadata \n\n13. data_channel_is_lifestyle: Is data channel 'Lifestyle'? \n\n14. data_channel_is_entertainment: Is data channel 'Entertainment'? \n\n15. data_channel_is_bus: Is data channel 'Business'? \n\n16. data_channel_is_socmed: Is data channel 'Social Media'? \n\n17. data_channel_is_tech: Is data channel 'Tech'? \n\n18. data_channel_is_world: Is data channel 'World'? \n\n19. kw_min_min: Worst keyword (min. shares) \n\n20. kw_max_min: Worst keyword (max. shares) \n\n21. kw_avg_min: Worst keyword (avg. shares) \n\n22. kw_min_max: Best keyword (min. shares) \n\n23. kw_max_max: Best keyword (max. shares) \n\n24. kw_avg_max: Best keyword (avg. shares) \n\n25. kw_min_avg: Avg. keyword (min. shares) \n\n26. kw_max_avg: Avg. keyword (max. shares) \n\n27. kw_avg_avg: Avg. keyword (avg. shares) \n\n28. self_reference_min_shares: Min. shares of referenced articles in Mashable \n\n29. self_reference_max_shares: Max. shares of referenced articles in Mashable \n\n30. self_reference_avg_sharess: Avg. shares of referenced articles in Mashable \n\n31. weekday_is_monday: Was the article published on a Monday? \n\n32. weekday_is_tuesday: Was the article published on a Tuesday? \n\n33. weekday_is_wednesday: Was the article published on a Wednesday? \n\n34. weekday_is_thursday: Was the article published on a Thursday? \n\n35. weekday_is_friday: Was the article published on a Friday? \n\n36. weekday_is_saturday: Was the article published on a Saturday? \n\n37. weekday_is_sunday: Was the article published on a Sunday? \n\n38. is_weekend: Was the article published on the weekend? \n\n39. LDA_00: Closeness to LDA topic 0 \n\n40. LDA_01: Closeness to LDA topic 1 \n\n41. LDA_02: Closeness to LDA topic 2 \n\n42. LDA_03: Closeness to LDA topic 3 \n\n43. LDA_04: Closeness to LDA topic 4 \n\n44. global_subjectivity: Text subjectivity \n\n45. global_sentiment_polarity: Text sentiment polarity \n\n46. global_rate_positive_words: Rate of positive words in the content \n\n47. global_rate_negative_words: Rate of negative words in the content \n\n48. rate_positive_words: Rate of positive words among non-neutral tokens \n\n49. rate_negative_words: Rate of negative words among non-neutral tokens \n\n50. avg_positive_polarity: Avg. polarity of positive words \n\n51. min_positive_polarity: Min. polarity of positive words \n\n52. max_positive_polarity: Max. polarity of positive words \n\n53. avg_negative_polarity: Avg. polarity of negative words \n\n54. min_negative_polarity: Min. polarity of negative words \n\n55. max_negative_polarity: Max. polarity of negative words \n\n56. title_subjectivity: Title subjectivity \n\n57. title_sentiment_polarity: Title polarity \n\n58. abs_title_subjectivity: Absolute subjectivity level \n\n59. abs_title_sentiment_polarity: Absolute polarity level \n\n60. shares: Number of shares (target)\n\n\n\n\n\nRelevant Papers:\n\n\n\nK. Fernandes, P. Vinagre and P. Cortez. A Proactive Intelligent Decision Support System for Predicting the Popularity of Online News. Proceedings of the 17th EPIA 2015 - Portuguese Conference on Artificial Intelligence, September, Coimbra, Portugal.\n\n\n\n\n\n\n\nCitation Request:\n\n\n\nK. Fernandes, P. Vinagre and P. Cortez. A Proactive Intelligent Decision Support System for Predicting the Popularity of Online News. Proceedings of the 17th EPIA 2015 - Portuguese Conference on Artificial Intelligence, September, Coimbra, Portugal.", "colleges": "Modified version for the automl benchmark.\nRegroups information for about 7800 different US colleges. Including geographical information, stats about the population attending and post graduation career earnings.", "nyc-taxi-green-dec-2016": "String datetime information extracted to numeric columns.Trip Record Data provided by the New York City Taxi and Limousine Commission (TLC) [http://www.nyc.gov/html/tlc/html/about/trip_record_data.shtml]. The dataset includes TLC trips of the green line in December 2016. Data was downloaded on 03.11.2018. For a description of all variables in the dataset checkout the TLC homepage [http://www.nyc.gov/html/tlc/downloads/pdf/data_dictionary_trip_records_green.pdf]. The variable 'tip_amount' was chosen as target variable. The variable 'total_amount' is ignored by default, otherwise the target could be predicted deterministically. The date variables 'lpep_pickup_datetime' and 'lpep_dropoff_datetime' (ignored by default) could be used to compute additional time features. In this version, we chose only trips with 'payment_type' == 1 (credit card), as tips are not included for most other payment types. We also removed the variables 'trip_distance' and 'fare_amount' to increase the importance of the categorical features 'PULocationID' and 'DOLocationID'.", "abalone": "Make target (age) numeric**Author**:   \n**Source**: Unknown -   \n**Please cite**:   \n\n1. Title of Database: Abalone data\n \n 2. Sources:\n \n    (a) Original owners of database:\n \tMarine Resources Division\n \tMarine Research Laboratories - Taroona\n \tDepartment of Primary Industry and Fisheries, Tasmania\n \tGPO Box 619F, Hobart, Tasmania 7001, Australia\n \t(contact: Warwick Nash +61 02 277277, wnash@dpi.tas.gov.au)\n \n    (b) Donor of database:\n \tSam Waugh (Sam.Waugh@cs.utas.edu.au)\n \tDepartment of Computer Science, University of Tasmania\n \tGPO Box 252C, Hobart, Tasmania 7001, Australia\n \n    (c) Date received: December 1995\n \n \n 3. Past Usage:\n \n    Sam Waugh (1995) \"Extending and benchmarking Cascade-Correlation\", PhD\n    thesis, Computer Science Department, University of Tasmania.\n \n    -- Test set performance (final 1044 examples, first 3133 used for training):\n \t24.86% Cascade-Correlation (no hidden nodes)\n \t26.25% Cascade-Correlation (5 hidden nodes)\n \t21.5%  C4.5\n \t 0.0%  Linear Discriminate Analysis\n \t 3.57% k=5 Nearest Neighbour\n       (Problem encoded as a classification task)\n \n    -- Data set samples are highly overlapped.  Further information is required\n \tto separate completely using affine combinations.  Other restrictions\n \tto data set examined.\n \n    David Clark, Zoltan Schreter, Anthony Adams \"A Quantitative Comparison of\n    Dystal and Backpropagation\", submitted to the Australian Conference on\n    Neural Networks (ACNN'96). Data set treated as a 3-category classification\n    problem (grouping ring classes 1-8, 9 and 10, and 11 on).\n \n    -- Test set performance (3133 training, 1044 testing as above):\n \t64%    Backprop\n \t55%    Dystal\n    -- Previous work (Waugh, 1995) on same data set:\n \t61.40% Cascade-Correlation (no hidden nodes)\n \t65.61% Cascade-Correlation (5 hidden nodes)\n \t59.2%  C4.5\n \t32.57% Linear Discriminate Analysis\n \t62.46% k=5 Nearest Neighbour\n \n \n 4. Relevant Information Paragraph:\n \n    Predicting the age of abalone from physical measurements.  The age of\n    abalone is determined by cutting the shell through the cone, staining it,\n    and counting the number of rings through a microscope -- a boring and\n    time-consuming task.  Other measurements, which are easier to obtain, are\n    used to predict the age.  Further information, such as weather patterns\n    and location (hence food availability) may be required to solve the problem.\n \n    From the original data examples with missing values were removed (the\n    majority having the predicted value missing), and the ranges of the\n    continuous values have been scaled for use with an ANN (by dividing by 200).\n \n    Data comes from an original (non-machine-learning) study:\n \n \tWarwick J Nash, Tracy L Sellers, Simon R Talbot, Andrew J Cawthorn and\n \tWes B Ford (1994) \"The Population Biology of Abalone (_Haliotis_\n \tspecies) in Tasmania. I. Blacklip Abalone (_H. rubra_) from the North\n \tCoast and Islands of Bass Strait\", Sea Fisheries Division, Technical\n \tReport No. 48 (ISSN 1034-3288)\n \n \n 5. Number of Instances: 4177\n \n \n 6. Number of Attributes: 8\n \n \n 7. Attribute information:\n \n    Given is the attribute name, attribute type, the measurement unit and a\n    brief description.  The number of rings is the value to predict: either\n    as a continuous value or as a classification problem.\n \n \tName\t\tData Type\tMeas.\tDescription\n \t----\t\t---------\t-----\t-----------\n \tSex\t\tnominal\t\t\tM, F, and I (infant)\n \tLength\t\tcontinuous\tmm\tLongest shell measurement\n \tDiameter\tcontinuous\tmm\tperpendicular to length\n \tHeight\t\tcontinuous\tmm\twith meat in shell\n \tWhole weight\tcontinuous\tgrams\twhole abalone\n \tShucked weight\tcontinuous\tgrams\tweight of meat\n \tViscera weight\tcontinuous\tgrams\tgut weight (after bleeding)\n \tShell weight\tcontinuous\tgrams\tafter being dried\n \tRings\t\tinteger\t\t\t+1.5 gives the age in years\n \n    Statistics for numeric domains:\n \n \t\tLength\tDiam\tHeight\tWhole\tShucked\tViscera\tShell\tRings\n \tMin\t0.075\t0.055\t0.000\t0.002\t0.001\t0.001\t0.002\t    1\n \tMax\t0.815\t0.650\t1.130\t2.826\t1.488\t0.760\t1.005\t   29\n \tMean\t0.524\t0.408\t0.140\t0.829\t0.359\t0.181\t0.239\t9.934\n \tSD\t0.120\t0.099\t0.042\t0.490\t0.222\t0.110\t0.139\t3.224\n \tCorrel\t0.557\t0.575\t0.557\t0.540\t0.421\t0.504\t0.628\t  1.0\n \n \n 8. Missing Attribute Values: None\n \n \n 9. Class Distribution:\n \n \tClass\tExamples\n \t-----\t--------\n \t1\t1\n \t2\t1\n \t3\t15\n \t4\t57\n \t5\t115\n \t6\t259\n \t7\t391\n \t8\t568\n \t9\t689\n \t10\t634\n \t11\t487\n \t12\t267\n \t13\t203\n \t14\t126\n \t15\t103\n \t16\t67\n \t17\t58\n \t18\t42\n \t19\t32\n \t20\t26\n \t21\t14\n \t22\t6\n \t23\t9\n \t24\t2\n \t25\t1\n \t26\t1\n \t27\t2\n \t29\t1\n \t-----\t----\n \tTotal\t4177\n \n Num Instances:     4177\n Num Attributes:    9\n Num Continuous:    8 (Int 1 / Real 7)\n Num Discrete:      1\n Missing values:    0 /  0.0%\n\n     name                      type enum ints real     missing    distinct  (1)\n   1 'Sex'                     Enum 100%   0%   0%     0 /  0%     3 /  0%   0% \n   2 'Length'                  Real   0%   0% 100%     0 /  0%   134 /  3%   0% \n   3 'Diameter'                Real   0%   0% 100%     0 /  0%   111 /  3%   0% \n   4 'Height'                  Real   0%   0% 100%     0 /  0%    51 /  1%   0% \n   5 'Whole weight'            Real   0%   0% 100%     0 /  0%  2429 / 58%  31% \n   6 'Shucked weight'          Real   0%   0% 100%     0 /  0%  1515 / 36%  10% \n   7 'Viscera weight'          Real   0%   0% 100%     0 /  0%   880 / 21%   3% \n   8 'Shell weight'            Real   0%   0% 100%     0 /  0%   926 / 22%   8% \n   9 'Class_Rings'             Int    0% 100%   0%     0 /  0%    28 /  1%   0%", "us_crime": "Ignores community name.**Author**:   \n  \n**Source**: Unknown - 2009  \n**Please cite**:   \n\nTitle: Communities and Crime\n \nAbstract: Communities within the United States. The data combines socio-economic data from the 1990 US Census, law enforcement data from the 1990 US LEMAS survey, and crime data from the 1995 FBI UCR.\n\nData Set Characteristics:  Multivariate\nAttribute Characteristics: Real\nAssociated Tasks: Regression\nNumber of Instances: 1994\nNumber of Attributes: 128\nMissing Values? Yes\nArea: Social\nDate Donated: 2009-07-13\n \nSource:\nCreator: Michael Redmond (redmond 'at' lasalle.edu); Computer Science; La Salle \nUniversity; Philadelphia, PA, 19141, USA\n-- culled from 1990 US Census, 1995 US FBI Uniform Crime Report, 1990 US Law Enforcement Management and Administrative Statistics Survey, available from ICPSR at U of Michigan.\n-- Donor: Michael Redmond (redmond 'at' lasalle.edu); Computer Science; La Salle University; Philadelphia, PA, 19141, USA\n-- Date: July 2009\n\nData Set Information:\nMany variables are included so that algorithms that select or learn weights for attributes could be tested. However, clearly unrelated attributes were not included; attributes were picked if there was any plausible connection to crime (N=122), plus the attribute to be predicted (Per Capita Violent Crimes). The variables included in the dataset involve the community, such as the percent of the population considered urban, and the median family income, and involving law enforcement, such as per capita number of police officers, and percent of officers assigned to drug units. The per capita violent crimes variable was calculated using population and the sum of crime variables considered violent crimes in the United States: murder, rape, robbery, and assault. There was apparently some controversy in some states concerning the counting of rapes. These resulted in missing values for rape, which resulted in incorrect values for per capita violent crime. These cities are not included in the dataset. Many of these omitted communities were from the midwestern USA. Data is described below based on original values. All numeric data was normalized into the decimal range 0.00-1.00 using an Unsupervised, equal-interval binning method. \nAttributes retain their distribution and skew (hence for example the population \nattribute has a mean value of 0.06 because most communities are small). E.g. An attribute described as 'mean people per household' is actually the normalized (0-1) version of that value. The normalization preserves rough ratios of values WITHIN an attribute (e.g. double the value for double the population within the available precision - except for extreme values (all values more than 3 SD above the mean are normalized to 1.00; all values more than 3 SD below the mean are nromalized to 0.00)).\n\nHowever, the normalization does not preserve relationships between values BETWEEN attributes (e.g. it would not be meaningful to compare the value for whitePerCap with the value for blackPerCap for a community)\nA limitation was that the LEMAS survey was of the police departments with at least 100 officers, plus a random sample of smaller departments. For our purposes, communities not found in both census and crime datasets were omitted. Many communities are missing LEMAS data.", "pol": "**Author**:   \n**Source**: Unknown -   \n**Please cite**:   \n\nThis is a commercial application described in Weiss & Indurkhya (1995). \n The data describes a telecommunication problem. No further information\n is available.\n \n Characteristics: (10000+5000) cases, 49 continuous attributes \n Source: collection of regression datasets by Luis Torgo (ltorgo@ncc.up.pt) at\n http://www.ncc.up.pt/~ltorgo/Regression/DataSets.html\n Original Source: The data in the original format can be obtained \n from http://www.cs.su.oz.au/~nitin", "SAT11-HAND-runtime-regression": "source: http://www.cs.ubc.ca/labs/beta/Projects/SATzilla/\nauthors: L. Xu, F. Hutter, H. Hoos, K. Leyton-Brown\ntranslator in coseal format: M. Lindauer with the help of Alexandre Frechette\nthe data do not distinguish between timeout, memout or crashes!\nthe status file will only have ok or timeout!\nIf features are \"?\", the instance was solved during feature computation.\n\nAlthough there is no necessary alignment and dependencies between the feature processing steps,\nthe steps were executed in a fixed alignment.\nTherefore, all feature steps depend on the previous executed ones.", "house_sales": "Date converted to year/mo/day numerics.This dataset contains house sale prices for King County, which includes Seattle. It includes homes sold between May 2014 and May 2015.\n\nIt contains 19 house features plus the price and the id columns, along with 21613 observations.\nIt's a great dataset for evaluating simple regression models.", "boston": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nThe Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\nprices and the demand for clean air', J. Environ. Economics & Management,\nvol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n...', Wiley, 1980.   N.B. Various transformations are used in the table on\npages 244-261 of the latter.\nVariables in order:\nCRIM     per capita crime rate by town\nZN       proportion of residential land zoned for lots over 25,000 sq.ft.\nINDUS    proportion of non-retail business acres per town\nCHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\nNOX      nitric oxides concentration (parts per 10 million)\nRM       average number of rooms per dwelling\nAGE      proportion of owner-occupied units built prior to 1940\nDIS      weighted distances to five Boston employment centres\nRAD      index of accessibility to radial highways\nTAX      full-value property-tax rate per $10,000\nPTRATIO  pupil-teacher ratio by town\nB        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\nLSTAT    % lower status of the population\nMEDV     Median value of owner-occupied homes in $1000's\n\n\nInformation about the dataset\nCLASSTYPE: numeric\nCLASSINDEX: last", "house_prices_nominal": "**Author**: Kaggle  \n\n**Source**: [original](https://www.kaggle.com/c/house-prices-advanced-regression-techniques) - 2011  \n\n**Please cite**: Dean De Cock (2011) Ames, Iowa: Alternative to the Boston Housing Data as an End of Semester Regression Project, Journal of Statistics Education, 19:3, DOI: 10.1080/10691898.2011.11889627  \n\n\n\nAsk a home buyer to describe their dream house, and they probably won't begin with the height of the basement ceiling or the proximity to an east-west railroad. But this playground competition's dataset proves that much more influences price negotiations than the number of bedrooms or a white-picket fence.\n\n\n\nWith 79 explanatory variables describing (almost) every aspect of residential homes in Ames, Iowa, this competition challenges you to predict the final price of each home. \n\n    \n\nSalePrice - the property's sale price in dollars. This is the target variable that you're trying to predict.\n\n\n\nMSSubClass: The building class\n\n\n\nMSZoning: The general zoning classification\n\n\n\nLotFrontage: Linear feet of street connected to property\n\n\n\nLotArea: Lot size in square feet\n\n\n\nStreet: Type of road access\n\n\n\nAlley: Type of alley access\n\n\n\nLotShape: General shape of property\n\n\n\nLandContour: Flatness of the property\n\n\n\nUtilities: Type of utilities available\n\n\n\nLotConfig: Lot configuration\n\n\n\nLandSlope: Slope of property\n\n\n\nNeighborhood: Physical locations within Ames city limits\n\n\n\nCondition1: Proximity to main road or railroad\n\n\n\nCondition2: Proximity to main road or railroad (if a second is present)\n\n\n\nBldgType: Type of dwelling\n\n\n\nHouseStyle: Style of dwelling\n\n\n\nOverallQual: Overall material and finish quality\n\n\n\nOverallCond: Overall condition rating\n\n\n\nYearBuilt: Original construction date\n\n\n\nYearRemodAdd: Remodel date\n\n\n\nRoofStyle: Type of roof\n\n\n\nRoofMatl: Roof material\n\n\n\nExterior1st: Exterior covering on house\n\n\n\nExterior2nd: Exterior covering on house (if more than one material)\n\n\n\nMasVnrType: Masonry veneer type\n\n\n\nMasVnrArea: Masonry veneer area in square feet\n\n\n\nExterQual: Exterior material quality\n\n\n\nExterCond: Present condition of the material on the exterior\n\n\n\nFoundation: Type of foundation\n\n\n\nBsmtQual: Height of the basement\n\n\n\nBsmtCond: General condition of the basement\n\n\n\nBsmtExposure: Walkout or garden level basement walls\n\n\n\nBsmtFinType1: Quality of basement finished area\n\n\n\nBsmtFinSF1: Type 1 finished square feet\n\n\n\nBsmtFinType2: Quality of second finished area (if present)\n\n\n\nBsmtFinSF2: Type 2 finished square feet\n\n\n\nBsmtUnfSF: Unfinished square feet of basement area\n\n\n\nTotalBsmtSF: Total square feet of basement area\n\n\n\nHeating: Type of heating\n\n\n\nHeatingQC: Heating quality and condition\n\n\n\nCentralAir: Central air conditioning\n\n\n\nElectrical: Electrical system\n\n\n\n1stFlrSF: First Floor square feet\n\n\n\n2ndFlrSF: Second floor square feet\n\n\n\nLowQualFinSF: Low quality finished square feet (all floors)\n\n\n\nGrLivArea: Above grade (ground) living area square feet\n\n\n\nBsmtFullBath: Basement full bathrooms\n\n\n\nBsmtHalfBath: Basement half bathrooms\n\n\n\nFullBath: Full bathrooms above grade\n\n\n\nHalfBath: Half baths above grade\n\n\n\nBedroom: Number of bedrooms above basement level\n\n\n\nKitchen: Number of kitchens\n\n\n\nKitchenQual: Kitchen quality\n\n\n\nTotRmsAbvGrd: Total rooms above grade (does not include bathrooms)\n\n\n\nFunctional: Home functionality rating\n\n\n\nFireplaces: Number of fireplaces\n\n\n\nFireplaceQu: Fireplace quality\n\n\n\nGarageType: Garage location\n\n\n\nGarageYrBlt: Year garage was built\n\n\n\nGarageFinish: Interior finish of the garage\n\n\n\nGarageCars: Size of garage in car capacity\n\n\n\nGarageArea: Size of garage in square feet\n\n\n\nGarageQual: Garage quality\n\n\n\nGarageCond: Garage condition\n\n\n\nPavedDrive: Paved driveway\n\n\n\nWoodDeckSF: Wood deck area in square feet\n\n\n\nOpenPorchSF: Open porch area in square feet\n\n\n\nEnclosedPorch: Enclosed porch area in square feet\n\n\n\n3SsnPorch: Three season porch area in square feet\n\n\n\nScreenPorch: Screen porch area in square feet\n\n\n\nPoolArea: Pool area in square feet\n\n\n\nPoolQC: Pool quality\n\n\n\nFence: Fence quality\n\n\n\nMiscFeature: Miscellaneous feature not covered in other categories\n\n\n\nMiscVal: $Value of miscellaneous feature\n\n\n\nMoSold: Month Sold\n\n\n\nYrSold: Year Sold\n\n\n\nSaleType: Type of sale\n\n\n\nSaleCondition: Condition of sale", "house_16H": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nThis database was designed on the basis of data provided by US Census\nBureau [http://www.census.gov] (under Lookup Access\n[http://www.census.gov/cdrom/lookup]: Summary Tape File 1). The data\nwere collected as part of the 1990 US census. These are mostly counts\ncumulated at different survey levels. For the purpose of this data set\na level State-Place was used. Data from all states was obtained. Most\nof the counts were changed into appropriate proportions.  There are 4\ndifferent data sets obtained from this database: House(8H) House(8L)\nHouse(16H) House(16L) These are all concerned with predicting the\nmedian price of the house in the region based on demographic\ncomposition and a state of housing market in the region. A number in\nthe name signifies the number of attributes of the data set. A\nfollowing letter denotes a very rough approximation to the difficulty\nof the task. For Low task difficulty, more correlated attributes were\nchosen as signified by univariate smooth fit of that input on the\ntarget. Tasks with High difficulty have had their attributes chosen to\nmake the modelling more difficult due to higher variance or lower\ncorrelation of the inputs to the target.\n\nOriginal source: DELVE repository of data.\nSource: collection of regression datasets by Luis Torgo (ltorgo@ncc.up.pt) at\nhttp://www.ncc.up.pt/~ltorgo/Regression/DataSets.html\nCharacteristics: 22784 cases, 17 continuous attributes.", "QSAR-TID-11": "**Author**: Dr Ivan Olier, Dr Jeremy Besnard, Dr Noureddin Sadawi, Dr Larisa Soldatova, Dr Crina Grosan, Prof Ross King, Dr Richard Bickerton, Prof Andrew Hopkins and Dr Willem van Hoorn  \n**Source**: MetaQSAR project - September 2015  \n**Please cite**:   \n\nThis dataset contains QSAR data (from ChEMBL version 17) showing activity values (unit is pseudo-pCI50) of several compounds on drug target TID: 11, and it has 5742 rows and 1026 features (including IDs and class feature: MOLECULE_CHEMBL_ID and MEDIAN_PXC50). The features represent FCFP 1024bit Molecular Fingerprints which were generated from SMILES strings. They were obtained using the Pipeline Pilot program, Dassault Syst\u00e8mes BIOVIA. Generating Fingerprints does not usually require missing value imputation as all bits are generated.", "QSAR-TID-10980": "**Author**: Dr Ivan Olier, Dr Jeremy Besnard, Dr Noureddin Sadawi, Dr Larisa Soldatova, Dr Crina Grosan, Prof Ross King, Dr Richard Bickerton, Prof Andrew Hopkins and Dr Willem van Hoorn  \n**Source**: MetaQSAR project - September 2015  \n**Please cite**:   \n\nThis dataset contains QSAR data (from ChEMBL version 17) showing activity values (unit is pseudo-pCI50) of several compounds on drug target TID: 10980, and it has 5766 rows and 1026 features (including IDs and class feature: MOLECULE_CHEMBL_ID and MEDIAN_PXC50). The features represent FCFP 1024bit Molecular Fingerprints which were generated from SMILES strings. They were obtained using the Pipeline Pilot program, Dassault Syst\u00e8mes BIOVIA. Generating Fingerprints does not usually require missing value imputation as all bits are generated.", "MIP-2016-regression": "source: http://plato.asu.edu/ftp/solvable.html\nauthors: Rolf-David Bergdoll\n\nPAR10 performances of modern solvers on the solvable instances of MIPLIB2010.\nhttp://miplib.zib.de/\n\nThe algorithm runtime data was directly taken from the '12 threads' table of\nH. Mittelmann's evaluations.\n\nThe features were generated using the MIP feature computation code from\nhttp://www.cs.ubc.ca/labs/beta/Projects/EPMs/\n\nTo record runtimes of the feature computations, runsolver was used: \nhttp://www.cril.univ-artois.fr/~roussel/runsolver/\n\nPart of Open Algorithm Challenge 2017 (\"Mira\")."}